# 作业3:Aliens游戏

**张祎扬  (181840326   181840326@smail.nju.edu.cn)**

**(南京大学  匡亚明学院，南京 210046)**

**摘要**：使用监督学习来模仿人玩游戏的动作。在这里我选择了四种算法，分别是NaiveBayes，Random Forest，AdaBoostM1,Logistic.利用非常优秀的机器学习包weka来构建模型，在训练时记录游戏状态作为训练集，并将训练出的模型应用于测试。比较不同算法的性能并尝试改进特征提取方法。

**关键词：**机器学习、监督学习、朴素贝叶斯、随机森林、AdaBoost、Logistic、weka

## 1.学习方法介绍

### 1.1 朴素贝叶斯NaiveBayes

#### 1.1.1 算法思想

朴素贝叶斯算法的**关键**在于认为模型中的各个特征都是独立的，它并没有考虑某些特征之间的相关性，这就使事情变得十分简单。所以在模型的各个属性的相关性较小的时候，朴素贝叶斯的性能可以更好地体现。

贝叶斯定理的本质是一个求概率的过程。就是在已知$$P(A|B)$$的情况下，如何求得$$P(B|A)$$.

首先解释条件概率的定义：

$$P(A|B)$$表示事件B已经发生的前提下，事件A发生的概率。它叫做**事件B发生下事件A的条件概率**。基本计算公式为
$$
P(A|B) = \frac{P(AB)}{P(B)}
$$
贝叶斯定理的有用之处，是因为我们可能会碰到这样的情况：$$P(A|B)$$很容易得到，但是却很难得出$$P(B|A)$$.但根据贝叶斯定理，就可以有如下推导：
$$
P(A|B) = \frac{P(AB)}{P(B)}\\
P(B|A) = \frac{P(AB)}{P(A)}\\
$$
联立以上两个式子，消去$$P(AB)$$,可以得到
$$
P(B|A) = \frac{P(A|B)*P(B)}{P(A)}
$$
朴素贝叶斯被广泛地应用于分类问题中，假设结果有几种类别，可以利用朴素贝叶斯定理分别求出结果属于每一类的概率，取概率最高的类别作为最后的预测类别。在本次作业中，就是对于现有的特征提取方法，收集训练数据(当前游戏状态和作出的动作所属的类别)。根据我对代码的理解，在recoder.java中将移动的类型(move type)定义为最后的类别。而应用的过程就是根据当前游戏局面的状态，根据分类器的学习结果，计算出各个类别的概率，**选择概率最高的类别并做出相应的动作**。

整个朴素贝叶斯分类过程分为三个阶段：

1. 准备阶段。确定特征属性，形成训练样本集合。在本次作业任务中，就是通过玩游戏，来记录各种数据。==根据我的理解，训练集的好坏其实对分类器的性能有很大的影响，而在本次任务中，数据的收集又很特殊，它需要靠我们手动去操作游戏。这就导致了每一个人的训练集都是完全不一样的，所以不同同学之间如果要比较分类器的性能，也是没有一个绝对的方法。在这一情况下，我觉得我更需要考虑的是怎么优化我的训练集。==一个方法是优化特征提取的函数，让它更有利于赢得游戏，当然这是作业内容2中的部分，我将稍后再讨论这一点。另一个方法就是我在手动操作的时候要尽量玩出**”漂亮“**的游戏，但这其实是一个很难的过程，~~首先就是我的游戏水平不怎么过关，老是玩死emm~~,然后就是，在玩游戏的过程中，==不仅要注意多玩几次，提高样本容量，更要注意考虑到多种情况，比如躲避怪物的子弹等，不能老是在原地不动，只是发射子弹，这样分类器习得的性能显然不是很优秀的。==

2. 分类器训练阶段。计算每个类别在训练样本中的出现频率，以及每个特征属性对每个类别的条件概率。

   设$$x=\{a_1,a_2,...,a_m\}$$为一个样本，其中$$a_1,...,a_m$$是$$x$$的属性，而$$C=\{y_1,y_2,...,y_n\}$$是一个类别集合。根据贝叶斯定理，假设各特征属性相互独立，各类别下各个特征属性的条件概率为$$P(a_1|y_1),P(a_2|y_1),...,P(a_m|y_1);P(a_2|y_2),...,P(a_m|y_2);...,P(a_m|y_m)$$,根据贝叶斯定理推导：
   $$
   P(y_i|x) = \frac{P(x|y_i)*P(y_i)}{P(x)}
   $$
   因为分母对于各个类别其实是常数，所以只要比较分子即可。
   $$
   P(x|y_i)P(y_i) = P(y_i)\prod_{j=1}^mP(a_j|y_i)
   $$

3. 应用阶段。使用分类器对待分类项进行分类。计算所有的$$P(y_i|x)$$,如果$$P(y_k|x)=max\{P(y_i|x),i=1,2,...,n\}$$,则$$x$$的类别是$$y_k$$.

#### 1.1.2 一些优化和修正

当特征属性是离散的，只要计算各类别出现的频率即可用来估计概率。但特征属性也可能是连续值，这时候通常假定其值服从高斯分布。
$$
g(x,\alpha,\sigma) = \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\alpha)^2}{2\sigma^2}}
$$
而$$P(a_k|y_i) = g(a_k,\alpha_{y_i},\sigma_{y_i})$$,因此只需要计算样本各个类别中此特征值的均值和标准差，带入上述公式即可。

另一个需要讨论的情况是$$P(a|y)=0$$，因为0乘任何数都为0，这实际上大大降低分类器的性能。解决这个问题的方法是引入Laplace校准，即对每一个类别下所有计数加一，这样避免了出现0的情况，同时当训练集数量充分大时，不会对结果产生什么影响。

注：以上简介参考了一些博客（主要是[1])和介绍机器学习算法的网站[2]。

### 1.2 随机森林Random Forest

随机森林的基本单元是决策树，它是一种将多棵决策树集成的算法。每棵决策树都是一个分类器，输入样本，每棵树会有一个分类结果。而随机森林集成了所有的分类投票结果，把投票次数最多的类别指定为最终的输出。

每棵树生成过程如下：

1. 如果训练集的个数是N，在N个训练集中随机取样，但是不能取完全相同的样本做训练集。（我的理解是这些小的集合中的元素可以有交叉，但是不能完全一样）。这个小集合就将是这一棵树的训练集。
2. 如果有M个变量，确定一个数m<<M,用来确定每棵树结点选择多少个变量。
3. 每棵树都尽可能扩张，没有剪枝。

从以上过程可以看出，树的生成过程是很随机的，这也减少了树与树之间的相关性。

而随机森林的错误率依赖于两个因素：

- 森林中任意两棵树的相关性。增加相关性会提高错误率。
- 森林中每棵树的分类能力。个体树的分类能力的增加可以增加整个森林的分类能力。

**袋外错误率out-of-bag(oob) error**

每棵树都是用不完全相同的训练集生长出来的，对于第$$k$$棵树的生长，原数据集中大约有$$\frac{1}{3}$$没有用到，它们称为第$$k$$棵树的oob样本。把这些没有用到的数据集用第$$k$$棵树去分类。用这种方式，每个case都经过了大约$$\frac{1}{3}$$的树的分类，把这些分类结果进行投票，并选择票数最多的作为最终的分类结果。最后用误分类个数占样本总数的比率作为随机森林的oob误分率。

根据我的理解，随机树的随机性体现在两个方面：一个是每棵树的样本选择的随机性，另一个是m值选择的随机性。由于这种随机性，使得随机森林的过拟合概率减少。同时它是一种集成的分类方式，所以有更强的分类性能。

以上参考了随机森林算法的描述文件[3].

### 1.3 Adaboost

在搜索网页获取资料的过程中，我了解到集成学习常见的两种方案为bagging和boosting.其中，bagging是一种基于投票的方案，boosting是一种基于改变原始数据集分布的迭代串行方案。鉴于以上我选择了bagging的代表算法Random Forest, 所以我打算再选择一种boosting算法AdaboostM1.

#### 1.3.1 Adaboost

Adaboost是一种用于二分类问题的集成方法。而M1则在它的基础上把问题扩展到多分类。

定义损失函数为指数损失函数$$L(y,f(x))=exp(-yf(x))$$,根据加型模型，第m轮的分类函数$$f_m(x)=f_{m-1}(x)+\alpha_mG_m(x)$$,其中，$$\alpha_m$$为基分类器$$G_m(x)$$的组合系数。AdaBoost采用前向分布(forward stagewise)这种贪心算法最小化损失函数，求解子模型的$$\alpha_m$$.
$$
\alpha_m=\frac{1}{2}log\frac{1-e_m}{e_m}
$$
其中，$$e_m$$为$$G_m(x)$$的分类误差率。第m+1轮第训练数据集权值分布$$D_{m+1}=(w_{m+1,1},...,w_{m+1,i},...,w_{m+1,N})$$
$$
w_{m+1,i}=\frac{w_{m,i}}{Z_m}exp(-\alpha_my_iG_m(x_i))
$$
其中，$$Z_m$$为规范化因子
$$
Z_m=\sum_{i=1}^{N}w_{m,i}*exp(-\alpha_my_iG_m(x_i))
$$
则得到最终分类器
$$
sign(f(x))=sign(\sum_{m=1}^{M}\alpha_mG_m(x))
$$
$$\alpha_m$$是$$e_m$$的单调递减函数，特别地，当$$e_m\leq\frac{1}{2}$$时，$$\alpha_m\geq0$$;当$$e_m>\frac{1}{2}$$时，即基分类器不满足弱可学习的条件，则应该停止迭代。具体算法的流程如下：

>1 $$D_1(i)=1/N$$ %Initialize the weight distribution
>
>2 for $$m=1,...,M$$:
>
>3 	learn base classifier $$G_m(x)$$;
>
>4 	if $$e_m>0.5$$ then back;
>
>5 	update $$\alpha_m$$ and $$D_{m+1}$$;
>
>6 end for

从算法步骤中我们可以看出，权重的更新方式为：
$$
D_{t+1}(i)=\begin{cases}
D_t(i)*e^{-\alpha_t} & ifh_t(x_i)=y_i,\\
D_t(i)*e^{\alpha_t} &if not.
\end{cases}
$$
一个样本是否被正确分类，它的权重将乘以不同的值。

可以看出，AdaBoost的核心步骤就是计算基学习器权重和样本权重分布。

#### 1.3.2 AdaBoostM1

AdaBoostM1算法在原算法的基础上，把二分类问题扩展为多分类问题。但它和原算法有一些不同点。

- 分类函数的形式发生了变化。没有使用$$sign()$$映射转化。
  $$
  H(x)=argmax\sum_{t=1}^{T}ln(\frac{1}{\beta_t})[h_t(x)=y]
  $$

- 权重更新函数作了一定的调整。如果一个样本被上一个分类器错误分类，那么它的权重不变，如果这个样本被上一个分类器正确分类，那么它的权重将乘以$$\frac{\epsilon_t}{1-\epsilon_t}$$,也就是说错误分类的样本权重值相对于正确分类的样本权重值扩大了$$\frac{1-\epsilon_t}{\epsilon_t}$$倍。

和随机森林不同的是，AdaBoost算法加入了迭代的过程，通过改变样本的权重来改变分类器模型函数。而随机森林则是一个少数服从多数的投票过程。

以上资料参考了github上的机器学习笔记[4]和一些博客[5-6]。

### 1.4 Logistic

Logistic回归输出一个0-1之间的离散结果。它通过使用其固有的logistic函数估计概率，来衡量因变量与一个或多个自变量之间的关系。自变量的取值范围可以从负无穷到正无穷，但是我们需要把输出控制在0和1.因此需要sigmoid函数。
$$
z=\theta_0=\theta_1*x_1+\theta_2*x_2+...\\
g(x)=\frac{1}{1+e^{-x}}\\
h=g(z)=\frac{1}{1+e^{-z}}
$$
其图像如下

<img src="/Users/zhangyiyang/Desktop/屏幕快照 2019-11-15 上午8.35.44.png" style="zoom:50%;" />需要一个损失函数来计算误分类的代价：
$$
Cost(h_\theta(x),y)=\begin{cases}
-log(h_\theta(x))&\text{if y = 1}\\
-log(1-h_\theta(x))&\text{if y = 0}
\end{cases}
$$
为了方便求梯度，可以改写成下面的式子
$$
-\frac{1}{m}[\sum_{i=1}^my^{(i)}logh_\theta(x^{(i)})+(1-y^{(i)})log(1-h_\theta(x^{(i)}))]
$$
通过梯度的帮助，可以更新$$\theta$$的值
$$
J=\frac{-1}{m}[\sum_{i=1}^my_ilogh_i+(1-y_i)log(1-h_i)]\\
\frac{\delta J}{\delta \theta_n}=\frac{-1}{m}[\sum_{i=1}^m\frac{y_i}{h_i}h_i^2x_n\frac{1-h_i}{h_i}+\frac{1-y_i}{1-h_i}(-h_i^2)x_n\frac{1-h_i}{h_i}]\\
\frac{\delta J}{\delta \theta_n}=\frac{-1}{m}[\sum_{i=1}^mx_n(1-h_i)y_i-x_nh_i(1-y_i)]\\
\frac{\delta J}{\delta \theta_n}=\frac{1}{m}x_i[\sum_{i=1}^mh_i-y_i]
$$
以上参考了来源[7-9].

## 2.学习性能对比

### 2.1第0关

在第0关中，我在一开始就往右移动到没有障碍物的地方，并且保持一定的节奏发射子弹，做到每一发子弹都消灭了一个怪物，把所有怪物都消灭在了第一排。

#### 2.1.1 朴素贝叶斯

学习结果如下

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午5.37.38.png)

可以看到分类的正确率为77.4611%，并不算很高。仔细观察细节可以发现，所有的右移动作都被分类正确，这大概是因为我在玩游戏的过程中几乎没有左移的动作，基本保持静止在原地。什么都不做的动作的分类准确率最高，发射子弹的动作的准确率只有50%左右。同时从混淆矩阵可以看出，模型更容易把动作分类为发射子弹。

运行test模式，发现模型学习到了我右移和发射子弹的动作，所以它在一开始就移动到了最右边并且一直发射子弹。但它并没有学习到我发射子弹的节奏，所以它一直不停地发射子弹，但是还是有一些怪物没有被打中，最后输掉了。

#### 2.1.2 随机森林

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午7.59.49.png)可以看出，正确被分类的比例是88%，和朴素贝叶斯相比提高了不少，它的分类精度也有所提高。它更倾向于把动作分类为什么也不做。

在运行test时，agent同样移到了最右边，但是它有一些左右摇摆的动作。它也保持一直发射子弹，但是因为无法规避子弹被击中。

#### 2.1.3 AdaBoostM1

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午8.05.49.png)它分类正确的比例和随机森林差不多，精度也差不多，但是ROC Area有所下降。同时游戏表现也是移到最右边然后不停射击。

#### 2.1.4 逻辑斯蒂回归

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午8.09.51.png)

正确率相比前两个有略微下降，但是比朴素贝叶斯还是高很多。精度表现和之前相差不大，同时ROC Area也不是很理想。在实际游戏过程中，agent除了移到画面最右边以外，有一些左右摇摆的行为。同时发射子弹的频率不够高，导致agent很容易被敌人的子弹击中。

### 2.2 第1关

在这一关中，我没有待在原地不动，而是尽量有一些移动去追击最低的怪物的移动，同时注意躲避怪物的攻击。

#### 2.2.1朴素贝叶斯

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午8.47.25.png)模型分类的准确率并不高，大约只有一半的被分类正确了。各项指标的表现都~~(很)~~不怎么样。在运行test的过程中，观察到agent有左右移动和追击怪物的行为，没有观察到明显的躲避怪物的子弹的行为，同时agent的行为有一些杂乱，难以理解。同时它学习到了一直发射子弹的动作。

#### 2.2.2 随机森林

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午8.49.13.png)随机森林的正确率比朴素贝叶斯好很多。它更倾向于把动作分类为什么都不做。在实际应用过程中，前期agent有明显的追踪怪物的行为和持续发射子弹的行为。但是后期的表现不好，它在最右端静止。

#### 2.2.3 AdaBoostM1

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午8.52.55.png)

它的准确率也不太高。它倾向于把动作分类为什么都不做的动作。

在实际应用中，agent一直保持静止，不停发射子弹。==竟然奇迹般地赢了==该模型对追踪怪物和躲避子弹的学习都不是很好。

#### 2.2.4 Logistic

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午8.55.07.png)它的分类准确率比朴素贝叶斯好很多。但是在test的时候，它更多的是无意义地左右移动，并且它对发射子弹这一个动作的学习效果不好，并没有怎么发射子弹。

### 2.3 第2关

在这一关中，我尽量避免设计到遮挡物。同时我尽量追踪怪物，但是我在玩游戏的过程中本身没有什么躲避子弹的行为。

#### 2.3.1 贝叶斯

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午8.59.42.png)分类的精确率等各项指标不是很好。它倾向于把什么都不做的动作分类到其他类别。

在实际应用中，agent并没有保持一直发射子弹。同时，它有表现出追踪怪物的行为，但是也有一些无意义的左右移动的表现。我无法判判断它是无规律地左右移动还是躲避子弹。

#### 2.3.2 随机森林

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午9.07.08.png)

随机森林的准确率很高。在实际应用中，agent有发射子弹的行为，但是几乎没有追踪怪物和躲避子弹的行为。

#### 2.3.3 AdaBoostM1

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午9.08.50.png)

可以看到它倾向于把所有类别预测为a类，准确率表现一般。在实际表现中，它先在原地不动，一直发射子弹，到还剩一个怪物的时候却停止发射子弹并且停在最左边。可以看出这个模型对追踪怪物的学习很差。

#### 2.3.4 逻辑斯蒂

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午9.11.23.png)准确率表现一般，倾向于把b类分类为a类。在实际应用中，agent一直发射子弹，并且表现出了一定的追踪怪物的行为。但是这种追踪行为并不是非常完善的。

### 2.4 第3关

在这一关中，由于缺少了障碍物的限制，我可以更自如地追赶怪物和躲避子弹。

#### 2.4.1 贝叶斯

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午9.33.38.png)

分类准确率依然不高，只有50左右。更倾向于把动作分类为左移。在实际应用中，agent对子弹发射的学习和怪物追踪的学习都不错。也表现出了躲避子弹的行为。

#### 2.4.2 随机森林

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午9.39.18.png)准确率在75左右。agent有比较明显的躲避子弹的行为，但是对怪物的追踪行为不是很明显。

#### 2.4.3AdaBoostM1

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午9.42.00.png)

准确率在70左右，仍然倾向于把所有类别分类为a。

在实际应用中，agent只是在原地不动不停的发射子弹，并没有学习到左右移动追击怪物和躲避子弹的行为。

#### 2.4.4 逻辑斯蒂

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午9.44.25.png)准确率不到70，TP率总体较低，从混淆矩阵也可以看出数据的总体分布是比较杂乱的。

在实际应用中，agent有左右移动的行为，但看起来不像是追击怪物。它表现出了一定的规避子弹的行为，但它并没有很好的保持发射子弹的行为。

### 2.5第4关

#### 2.5.1贝叶斯

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午10.00.46.png)

分类的准确率是60不到。倾向于把动作分类为右移。在实际应用中，agent没有体现出很好的追踪怪物左右移动的性能。

#### 2.5.2 随机森林

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午10.04.01.png)随机森林的准确率超过了80，算是比较高的了，同时它的FP率也比较低，总的来说表现不错。在实际应用中，agent对发射子弹的学习效果比较好，也有一定程度表现出追踪怪物的左右移动，但是它的规避子弹的能力没有体现出来，最后被击中了。

#### 2.5.3 AdaBoostM1

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午10.19.44.png)

准确率超过70%,仍旧是倾向于把所有类别预测为a类。在实际应用中，agent并没有追踪击打怪物的能力，而是静止在原地不动，发射子弹。同时也没有规避子弹的行为。

#### 2.5.4 逻辑斯蒂

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-14 下午10.22.25.png)分类的准确率在75左右，FP相对之前的比较低。在实际应用中有一定的追踪怪物的行为和规避子弹的行为。

### 2.6 总结

朴素贝叶斯虽然在数据上不是特别好看，准确率一直不太高，但是在实际应用中的表现还不错。它基本上学习了发射子弹的动作。随机森林的准确率基本上一直是最高的，在实际表现中也表现出了一些对怪物的追踪和对子弹的规避。AdaBoostM1的分类一直比较暴力，它基本上把所有的都分为a类，在实际应用中，agent基本上一直都是在原地不动，保持一直发射子弹，但是基本没有对怪物的追击和规避子弹的行为。逻辑斯蒂对发射子弹的行为的学习不是特别完善，表现较其他稍有逊色，同时它也没有很好地学习追踪怪物的行为，它的左右移动显得有些没有章法，有很大的随机性。

于我自己而言，这整个过程本身是非常主观的。这些学习首先依赖于我自己的操作，它们只能模仿我的动作。在实际打游戏的过程中，我并不是特别擅长打这种游戏。我花了大量的时间尝试，想要打出一场完美的游戏，但实际上很难兼顾到各个方面。又要不停发射子弹，还要追踪怪物，还要躲避怪物发射的子弹。在一局游戏中，这样的机会是很少的。甚至我可以在原地不动，只依靠控制发射子弹的节奏就直接把怪物消灭在第一行。但模型并不能学习到这个节奏，而它们又不能学习到我的左右移动和规避子弹，所以结果会很糟糕。所以在玩游戏的过程中，我不仅要获得游戏的胜利，更要在一局游戏中体现出更多更复杂的情况，这样才能有利于模型的学习。~~但是我的游戏水平真的特别菜~~,从模型的分析结果也可以看出，各种准确率之类的指标其实挺低的，但是我真的尽力了……

从以上模型可以看出，从整体上来说，对于追击怪物和躲避子弹的学习是比较困难的，一个是因为这些情况本身比较复杂，另一个就是我以上提到的，想要在玩游戏的过程中很好的体现出这些过程是很有难度的。

## 3.修改特征提取方法

原特征提取函数只记录屏幕上每个位置的信息，我觉得这是不够的。当前模型缺少的是规避炸弹的能力和左右移动追踪怪物的能力，所以改进的方法应该服务于这两个目的。解决如何规避炸弹的问题，我的想法是记录agent和炸弹的距离。解决追踪怪物的能力，我的解决方案是记录位于agent两侧的怪物的数量。一般情况下agent倾向于往怪物数量多的一侧移动。

改进后的部分代码如下：

```java
public static double[] featureExtract(StateObservation obs){
        
        double[] feature = new double[456];  // 448 + 4 + 1(class)
        
        // 448 locations
        int[][] map = new int[32][14];
        int left=0;
        int right=0;
        int bomb=0;
        Vector2d avatar_position = obs.getAvatarPosition();
        // Extract features
        LinkedList<Observation> allobj = new LinkedList<>();
        if( obs.getImmovablePositions()!=null )
            for(ArrayList<Observation> l : obs.getImmovablePositions()) allobj.addAll(l);
        if( obs.getMovablePositions()!=null )
            for(ArrayList<Observation> l : obs.getMovablePositions()) allobj.addAll(l);
        if( obs.getNPCPositions()!=null )
            for(ArrayList<Observation> l : obs.getNPCPositions()){
                for(Observation npc_ob : l){
                    //int x=(int)(npc_ob.position.x/25);
                    if(npc_ob.position.x<avatar_position.x)left++;
                    if(npc_ob.position.x>avatar_position.x)right++;
                }
                allobj.addAll(l);
            }
        
        for(Observation o : allobj){
            Vector2d p = o.position;
            int x = (int)(p.x/25);
            int y= (int)(p.y/25);
            map[x][y] = o.itype;
            if(o.itype==5 && Math.abs(o.position.x-avatar_position.x)<25)bomb=1;
        }
        for(int y=0; y<14; y++)
            for(int x=0; x<32; x++)
                feature[y*32+x] = map[x][y];
        
        // 4 states
        feature[448] = obs.getGameTick();
        feature[449] = obs.getAvatarSpeed();
        feature[450] = obs.getAvatarHealthPoints();
        feature[451] = obs.getAvatarType();
        feature[452] = left;
        feature[453] = right;
        feature[454] = bomb;
        
        return feature;
		}

public static Instances datasetHeader(){
        FastVector attInfo = new FastVector();
        // 448 locations
        for(int y=0; y<14; y++){
            for(int x=0; x<32; x++){
                Attribute att = new Attribute("object_at_position_x=" + x + "_y=" + y);
                attInfo.addElement(att);
            }
        }
        Attribute att = new Attribute("GameTick" ); attInfo.addElement(att);
        att = new Attribute("AvatarSpeed" ); attInfo.addElement(att);
        att = new Attribute("AvatarHealthPoints" ); attInfo.addElement(att);
        att = new Attribute("AvatarType" ); attInfo.addElement(att);
        att = new Attribute("left number");attInfo.addElement(att);
        att = new Attribute("right number");attInfo.addElement(att);
        att = new Attribute("bomb is detected");attInfo.addElement(att);
        //class
        FastVector classes = new FastVector();
        classes.addElement("0");
        classes.addElement("1");
        classes.addElement("2");
        classes.addElement("3");
        att = new Attribute("class", classes);        
        attInfo.addElement(att);
        
        Instances instances = new Instances("AliensData", attInfo, 0);
        instances.setClassIndex( instances.numAttributes() - 1);
        
        return instances;
    }
```



## 4.学习性能对比

在这里因为时间原因我就不把每一关的对比放上来了。由于第三关没有障碍物的限制，我可以更自如地移动，所以我把第三关的结果放上来。

### 4.1 朴素贝叶斯

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-15 上午9.15.31.png)

emm可以看到朴素贝叶斯的正确率依然只有一半左右，而且各类别的误分类率都不低。但是在实际应用中，agent表现出了比较明显的追踪怪物的性能，可以看到它对追踪怪物和发射子弹的行为的学习还是比较成功的。

### 4.2 随机森林

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-15 上午9.20.12.png)准确率超过了百分之七十，误分类率相比于朴素贝叶斯减少了许多，FPrate都基本低于0.1了。ROC Area的值也增加了不少。在实际应用中，agent表现出了非常明显的追踪怪物的行为，也有一定的躲避怪物的行为。基本上消灭了所有怪物。

### 4.3 AdaBoostM1

![](/Users/zhangyiyang/Desktop/屏幕快照 2019-11-15 上午9.25.57.png)准确率在63左右，和之前的情况很类似，AdaBoostM1算法还是倾向于把所有的动作分类为第一类。在实际应用中，agent仍然表现为在原地不动保持发射子弹的姿势。

#### 4.4 Logistic

<img src="/Users/zhangyiyang/Desktop/屏幕快照 2019-11-15 上午9.29.18.png" style="zoom:50%;" />

准确率64左右，误分类为b类的概率比较高。在实际应用中，agent表现出了比较优秀的持续射击能力和追踪怪物左右移动的能力，最终赢了。它有一定的左右移动规避炸弹的行为。

### 4.5 总结

由于样本容量太小，同时我自己在玩游戏的过程中有比较强的不确定性，所以这些学习的性能只能用作一个参考。同时，在修改特征提取方法前后进行对比的过程中，我并不能做到两次玩游戏都玩的一模一样，所以是否可以看到性能提升很大程度上也和训练集有关。即使性能其实没有提升，假如你玩的更好了，结果也会有一些明显的提升。退一步说，就算模型真的得到了改进，假如训练集不够优秀，也可以造成表面上的性能下降。所以从这个角度上来说，我觉得这些数据只是具有参考价值。

从数据上来看，朴素贝叶斯在数据上是最不好看的，它的准确率最低，各项指标也没有其他三种好，明显差一截。其他三个算法在数据上相差不大。但是在实际应用中，朴素贝叶斯的表现还是不错的，因为它的误分类率并不低，所以它的行为其实有一些随机性，反而会容易杀到怪物。随机森林算法和AdaBoostM1的准确率一直是最高的，和贝叶斯相比，这也体现出了集成学习的明显优势。其中，随机森林的表现比较优秀，不仅准确率高，在实际应用中agent的表现也比较好，追踪怪物的行为比较明显，也保持一直发射子弹，也可以在一定程度上看出规避子弹的行为。但是AdaBoostM1在所有关卡中都倾向于把动作分类为a类，它的分类结果是十分简单粗暴的。在实际应用中，agent永远保持在原地不动，一直发射子弹，几乎没有规避子弹和左右移动追踪怪物的行为，是非常不灵活的。逻辑斯蒂算法的准确率略微逊色于两种集成算法，但也比贝叶斯算法优秀许多。在实际应用中，逻辑斯蒂的表现也是比较优秀的，表现出了左右移动追击怪物，也有规避子弹的行为。

总的来说，在改进了特征提取方法以后，虽然在指标上没有明显的提升，但是在实际应用时，我明显地感觉到agent左右移动追击怪物的能力增加了不少。但对于规避子弹的能力的提升我并没有明显的感觉。我觉得首先是因为这个行为本身比较难学习，其次我的特征提取方法的改进对于学习规避子弹这个行为还是远远不够的，再就是我在玩游戏的过程中也并没有展现一个比较完美的训练集（这实在是个人水平有限，我已经不知道玩了多少轮了qwq）。顺便一点感想，玩游戏的能力有时候挺重要的:)

## 5.结束语

这次实验对我更多的是一个探索和比较的过程，鉴于它本身的影响因素很多，导致结果并不是绝对的客观。但我觉得更重要的是，这一过程中，通过自己的探索，去比较不同的算法之间的优劣，去思考怎么提升模型的学习性能。以及在无数次的玩游戏过程中思考，怎么表现才能让训练集更为完美，才能让模型尽可能地学习更多的技能。

**致谢：**也许是我的JAVA版本的问题，在打开weka.jar包的时候一直出错。最后我暂时的解决方案是在虚拟机里重新安装了一个IDE。非常感谢刘驭壬助教对我的帮助。

**References:**

[1]https://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html

[2]https://www.machinelearningplus.com/predictive-modeling/how-naive-bayes-algorithm-works-with-example-and-full-code/

[3]https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#inter

[4]https://github.com/Vay-keen/Machine-learning-learning-notes/blob/master/周志华《Machine%20Learning》学习笔记(10)--集成学习.md

[5]https://www.jianshu.com/p/121980ea415d

[6]https://www.cnblogs.com/en-heng/p/5974371.html

[7]https://hackernoon.com/introduction-to-machine-learning-algorithms-logistic-regression-cbdd82d81a36

[8]https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html

[9]http://www.sohu.com/a/231549006_129720